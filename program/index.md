---
title: PACT 2024 Technical program
description: Preliminary program
id:           program
layout:       page_sidebar
show_sidebar: true
---

# Schedule

* [Sunday, October 13, 2024](#sunday-october-13-2024)
* [Monday, October 14, 2024](#monday-october-14-2024)
* [Tuesday, October 15, 2024](#tuesday-october-15-2024)
* [Wednesday, October 16, 2024](#wednesday-october-16-2024)

### Sunday, October 13, 2024

<table class="table table-striped">
	<thead>
		<th>Time</th>
		<th>What</th>
	</thead>
	<tr>
		<td>08:00</td>
		<td><b>Tutorial:</b> QVT: The Quantum Visualization Toolkit</td>
	</tr>
	<tr>
		<td>12:00</td>
		<td>Lunch (provided)</td>
	</tr>
	<tr>
		<td>13:30</td>
		<td><b>Workshop:</b> The 4th International Workshop on Machine Learning for Software Hardware Co-Design (MLS/H)</td>
	</tr>
	<tr>
		<td>18:00</td>
		<td>Reception and Posters</td>
	</tr>
</table>

### Monday, October 14, 2024

<table class="table table-striped">
	<thead>
		<th>Time</th>
		<th>What</th>
	</thead>
	<tr>
		<td>08:00</td>
		<td>Opening</td>
	</tr>
	<tr>
		<td>08:30</td>
		<td>Keynote 1</td>
	</tr>
	<tr>
		<td>09:30</td>
		<td>Break</td>
	</tr>
	<tr>
		<td>10:00</td>
		<td>
			<b>Session 1: Machine Learning (4 papers)</b>
			<ul>
				<li><b>GraNNDis:</b> Fast Distributed Graph Neural Network Training Framework for Multi-Server Clusters</li>
				<li><b>Activation Sequence Caching:</b> High-Throughput and Memory-Efficient Generative Inference with a Single GPU</li>
				<li><b>Improving Throughput-oriented LLM Inference with CPU Computations</b></li>
				<li><b>BOOM:</b> Use your Desktop to Accurately Predict the Performance of Large Deep Neural Networks</li>
			</ul>
		</td>
	</tr>
	<tr>
		<td>12:00</td>
		<td>Lunch (provided)</td>
	</tr>
	<tr>
		<td>13:30</td>
		<td>
			<b>Session 2: Architecture and Application Co-design (3 papers)</b>
			<ul>
				<li><b>Demystifying Distributed Optimization Algorithms on a Real-World Processing-In-Memory Architecture</b></li>
				<li><b>ZeD:</b> A Generalized Accelerator for Variably Sparse Matrix Computations in ML</li>
				<li><b>A Parallel Hash Table for Streaming Applications</b></li>
			</ul>
		</td>
	</tr>
	<tr>
		<td>15:00</td>
		<td>Break</td>
	</tr>
	<tr>
		<td>15:30</td>
		<td>
			<b>Session 3: Parallelism (3 papers)</b>
			<ul>
				<li><b>Leveraging Difference Recurrence Relations for High-Performance GPU Genome Alignment</b></li>
				<li><b>ACE:</b> Efficient GPU Kernel Concurrency for Input-Dependent Irregular Computational Graphs</li>
				<li><b>Optimizing Tensor Computation Graphs with Equality Saturation and Monte Carlo Tree Search</b></li>
			</ul>
		</td>
	</tr>
	<tr>
		<td>17:30</td>
		<td>Business Meeting</td>
	</tr>
</table>

### Tuesday, October 15, 2024

<table class="table table-striped">
	<thead>
		<th>Time</th>
		<th>What</th>
	</thead>
	<tr>
		<td>08:30</td>
		<td>Keynote 2</td>
	</tr>
	<tr>
		<td>09:30</td>
		<td>Break</td>
	</tr>
	<tr>
		<td>10:00</td>
		<td>
			<b>Session 4: Compilers (4 papers)</b>
			<ul>
				<li><b>A Transducers-based Programming Framework for Efficient Data Transformation</b></li>
				<li><b>MIREncoder:</b> Multi-modal IR-based Pretrained Embeddings for Performance Optimizations</li>
				<li><b>Parallel Loop Locality Analysis for Symbolic Thread Counts</b></li>
				<li><b>PipeGen:</b> Automated Transformation of a Single-Core Pipeline into a Multicore Pipeline for a Given Memory Consistency Model</li>
			</ul>
		</td>
	</tr>
	<tr>
		<td>12:00</td>
		<td>Lunch (provided)</td>
	</tr>
	<tr>
		<td>13:30</td>
		<td>
			<b>Session 5: Security (4 papers)</b>
			<ul>
				<li><b>Defensive ML:</b> Adversarial Machine Learning as a Practical Architectural Defense for Side Channels</li>
				<li><b>Toast:</b> A Heterogeneous Memory Management System</li>
				<li><b>BoostCom:</b> Towards Efficient Universal Fully Homomorphic Encryption by Boosting the Word-wise Comparisons</li>
				<li><b>SZKP:</b> A Scalable Accelerator Architecture for Zero-Knowledge Proofs</li>
			</ul>
		</td>
	</tr>
	<tr>
		<td>15:30</td>
		<td>Break</td>
	</tr>
	<tr>
		<td>16:00</td>
		<td>
			<b>Session 6: Quantum & Neuromorphic (3 papers)</b>
			<ul>
				<li><b>Recompiling QAOA Circuits on Various Rotational Directions</b></li>
				<li><b>Faster and More Reliable Quantum SWAPs via Native Gates</b></li>
				<li><b>NavCim:</b> Comprehensive Design Space Exploration for Analog Computing-in-Memory Architectures</li>
			</ul>
		</td>
	</tr>
	<tr>
		<td>18:00</td>
		<td><a href="/attend/#conference-dinner">Conference dinner</a></td>
	</tr>
</table>

### Wednesday, October 16, 2024

<table class="table table-striped">
	<thead>
		<th>Time</th>
		<th>What</th>
		<th>Where</th>
	</thead>
	<tr>
		<td>08:00</td>
		<td>
			<b>Session 7: Memory (3 papers)</b>
			<ul>
				<li><b>MORSE:</b> Memory Overwrite Time Guided Soft Writes to Improve ReRAM Energy and Endurance</li>
				<li><b>Trimma:</b> Trimming Metadata Storage and Latency for Hybrid Memory Systems</li>
				<li><b>Chimera:</b> Leveraging Hybrid Offsets for Efficient Data Prefetching</li>
			</ul>
		</td>
	</tr>
	<tr>
		<td>09:30</td>
		<td>Break</td>
	</tr>
	<tr>
		<td>10:00</td>
		<td>SRC poster winners presentations</td>
	</tr>
	<tr>
		<td>11:00</td>
		<td>
			<b>Session 8: Address Translation, Coherence, and Communication (3 papers)</b>
			<ul>
				<li><b>Rethinking Page Table Structure for Fast Address Translation in GPUs: A Fixed-Size Hashed Page Table</b></li>
				<li><b>Taming the Acceleration Tax:</b> Enabling New Opportunities for Fine-Grained Disaggregated Accelerator-Level Parallelism</li>
				<li><b>vSPACE:</b> Supporting Parallel Network Packet Processing in Virtualized Environments through Dynamic Core Management</li>
			</ul>
		</td>
	</tr>
	<tr>
		<td>12:30</td>
		<td>Closing</td>
	</tr>
</table>

<br/>
{% include keynotes.html %}

<br/>
{% include list_of_papers.md %}
